/**
 * =============================================================================
 * QUEUE SERVICE - Async Processing for Scalability
 * =============================================================================
 * 
 * CRITICAL FOR MILLIONS OF USERS:
 * - Async broadcast processing
 * - Push notification batching
 * - Background job processing
 * - Retry logic for failed operations
 * 
 * MODES:
 * 1. In-Memory Queue (Development/Small scale)
 * 2. Redis/Bull Queue (Production/Large scale) - AWS SQS ready
 * 
 * AWS DEPLOYMENT:
 * - Can be replaced with AWS SQS for even larger scale
 * - Or use Bull with ElastiCache Redis
 * 
 * =============================================================================
 */

import { logger } from './logger.service';
import { EventEmitter } from 'events';
import { redisService } from './redis.service';

// =============================================================================
// TYPES
// =============================================================================

export interface QueueJob<T = any> {
  id: string;
  type: string;
  data: T;
  priority: number;
  attempts: number;
  maxAttempts: number;
  createdAt: number;
  processAfter?: number;
  error?: string;
}

export type JobProcessor<T = any> = (job: QueueJob<T>) => Promise<void>;

// =============================================================================
// IN-MEMORY QUEUE (Development / Single Server)
// =============================================================================

class InMemoryQueue extends EventEmitter {
  private queues: Map<string, QueueJob[]> = new Map();
  private processors: Map<string, JobProcessor> = new Map();
  private processing: Set<string> = new Set();
  private isRunning: boolean = false;
  private processInterval: ReturnType<typeof setInterval> | null = null;
  
  // Configuration
  private readonly concurrency: number = 10;
  private readonly pollInterval: number = 100; // ms
  
  constructor() {
    super();
    this.start();
  }
  
  /**
   * Add a job to the queue
   */
  async add<T>(
    queueName: string, 
    type: string, 
    data: T, 
    options?: {
      priority?: number;
      delay?: number;
      maxAttempts?: number;
    }
  ): Promise<string> {
    const job: QueueJob<T> = {
      id: `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      type,
      data,
      priority: options?.priority ?? 0,
      attempts: 0,
      maxAttempts: options?.maxAttempts ?? 3,
      createdAt: Date.now(),
      processAfter: options?.delay ? Date.now() + options.delay : undefined
    };
    
    if (!this.queues.has(queueName)) {
      this.queues.set(queueName, []);
    }
    
    const queue = this.queues.get(queueName)!;
    
    // Insert by priority (higher priority first)
    const insertIndex = queue.findIndex(j => j.priority < job.priority);
    if (insertIndex === -1) {
      queue.push(job);
    } else {
      queue.splice(insertIndex, 0, job);
    }
    
    logger.debug(`Job ${job.id} added to queue ${queueName} (type: ${type})`);
    this.emit('job:added', { queueName, job });
    
    return job.id;
  }
  
  /**
   * Add multiple jobs at once (batch)
   */
  async addBatch<T>(
    queueName: string,
    jobs: { type: string; data: T; priority?: number }[]
  ): Promise<string[]> {
    const ids: string[] = [];
    for (const job of jobs) {
      const id = await this.add(queueName, job.type, job.data, { priority: job.priority });
      ids.push(id);
    }
    return ids;
  }
  
  /**
   * Register a processor for a queue
   */
  process(queueName: string, processor: JobProcessor): void {
    this.processors.set(queueName, processor);
    logger.info(`Processor registered for queue: ${queueName}`);
  }
  
  /**
   * Start processing jobs
   */
  start(): void {
    if (this.isRunning) return;
    
    this.isRunning = true;
    this.processInterval = setInterval(() => this.tick(), this.pollInterval);
    logger.info('üöÄ Queue processor started');
  }
  
  /**
   * Stop processing jobs
   */
  stop(): void {
    this.isRunning = false;
    if (this.processInterval) {
      clearInterval(this.processInterval);
      this.processInterval = null;
    }
    logger.info('‚èπÔ∏è Queue processor stopped');
  }
  
  /**
   * Process tick - check for jobs to process
   */
  private async tick(): Promise<void> {
    if (this.processing.size >= this.concurrency) return;
    
    for (const [queueName, queue] of this.queues) {
      const processor = this.processors.get(queueName);
      if (!processor) continue;
      
      // Find next processable job
      const jobIndex = queue.findIndex(job => {
        if (this.processing.has(job.id)) return false;
        if (job.processAfter && Date.now() < job.processAfter) return false;
        return true;
      });
      
      if (jobIndex === -1) continue;
      
      const job = queue[jobIndex];
      this.processing.add(job.id);
      
      // Process asynchronously
      this.processJob(queueName, job, processor, jobIndex);
      
      // Respect concurrency limit
      if (this.processing.size >= this.concurrency) break;
    }
  }
  
  /**
   * Process a single job
   */
  private async processJob(
    queueName: string, 
    job: QueueJob, 
    processor: JobProcessor,
    _jobIndex: number
  ): Promise<void> {
    try {
      job.attempts++;
      await processor(job);
      
      // Success - remove from queue
      const queue = this.queues.get(queueName);
      if (queue) {
        const idx = queue.indexOf(job);
        if (idx !== -1) queue.splice(idx, 1);
      }
      
      this.emit('job:completed', { queueName, job });
      logger.debug(`Job ${job.id} completed (${queueName})`);
      
    } catch (error: any) {
      job.error = error.message;
      
      if (job.attempts >= job.maxAttempts) {
        // Max retries reached - move to dead letter
        const queue = this.queues.get(queueName);
        if (queue) {
          const idx = queue.indexOf(job);
          if (idx !== -1) queue.splice(idx, 1);
        }
        
        this.emit('job:failed', { queueName, job, error: error.message });
        logger.error(`Job ${job.id} failed permanently: ${error.message}`);
      } else {
        // Schedule retry with exponential backoff
        job.processAfter = Date.now() + Math.pow(2, job.attempts) * 1000;
        this.emit('job:retry', { queueName, job, attempt: job.attempts });
        logger.warn(`Job ${job.id} failed, retry ${job.attempts}/${job.maxAttempts}`);
      }
    } finally {
      this.processing.delete(job.id);
    }
  }
  
  /**
   * Get queue stats
   */
  getStats(): {
    queues: { name: string; pending: number; processing: number }[];
    totalPending: number;
    totalProcessing: number;
  } {
    const queueStats = Array.from(this.queues.entries()).map(([name, jobs]) => ({
      name,
      pending: jobs.length,
      processing: jobs.filter(j => this.processing.has(j.id)).length
    }));
    
    return {
      queues: queueStats,
      totalPending: queueStats.reduce((sum, q) => sum + q.pending, 0),
      totalProcessing: this.processing.size
    };
  }
}

// =============================================================================
// REDIS QUEUE (Production / Horizontal Scaling / Persistent)
// =============================================================================
/**
 * PRODUCTION-GRADE REDIS QUEUE
 * 
 * SCALABILITY: 
 * - Jobs persist across server restarts
 * - Shared across all ECS tasks/containers
 * - Uses Redis LPUSH/BRPOP for reliable FIFO queue
 * - Supports millions of jobs per day
 * 
 * EASY UNDERSTANDING:
 * - Same interface as InMemoryQueue
 * - Auto-reconnects on Redis failure
 * - Dead letter queue for failed jobs
 * 
 * MODULARITY:
 * - Can be swapped for AWS SQS later
 * - Implements same IQueue interface
 * 
 * CODING STANDARDS:
 * - Uses existing redisService
 * - Follows same patterns as cache.service.ts
 */
class RedisQueue extends EventEmitter {
  private processors: Map<string, JobProcessor> = new Map();
  private processing: Set<string> = new Set();
  private isRunning: boolean = false;
  private pollIntervals: Map<string, NodeJS.Timeout> = new Map();
  
  // Configuration
  private readonly concurrency: number = 10;
  private readonly pollInterval: number = 1000; // 1 second for Redis (less aggressive)
  private readonly queuePrefix: string = 'queue:';
  private readonly deadLetterPrefix: string = 'dlq:';
  
  constructor() {
    super();
    logger.info('üöÄ Redis Queue initialized (Production Mode)');
  }
  
  /**
   * Get Redis key for a queue
   */
  private getQueueKey(queueName: string): string {
    return `${this.queuePrefix}${queueName}`;
  }
  
  /**
   * Get Redis key for dead letter queue
   */
  private getDeadLetterKey(queueName: string): string {
    return `${this.deadLetterPrefix}${queueName}`;
  }
  
  /**
   * Add a job to the queue
   * Uses Redis LPUSH for O(1) insertion
   */
  async add<T>(
    queueName: string, 
    type: string, 
    data: T, 
    options?: {
      priority?: number;
      delay?: number;
      maxAttempts?: number;
    }
  ): Promise<string> {
    const job: QueueJob<T> = {
      id: `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      type,
      data,
      priority: options?.priority ?? 0,
      attempts: 0,
      maxAttempts: options?.maxAttempts ?? 3,
      createdAt: Date.now(),
      processAfter: options?.delay ? Date.now() + options.delay : undefined
    };
    
    const queueKey = this.getQueueKey(queueName);
    
    try {
      // Use LPUSH to add to head of list (FIFO with BRPOP)
      await redisService.lPush(queueKey, JSON.stringify(job));
      
      logger.debug(`Redis Queue: Job ${job.id} added to ${queueName} (type: ${type})`);
      this.emit('job:added', { queueName, job });
      
      return job.id;
    } catch (error: any) {
      logger.error(`Redis Queue: Failed to add job to ${queueName}:`, error.message);
      throw error;
    }
  }
  
  /**
   * Add multiple jobs at once (batch)
   * SCALABILITY: Uses Redis pipeline for efficiency
   */
  async addBatch<T>(
    queueName: string,
    jobs: { type: string; data: T; priority?: number }[]
  ): Promise<string[]> {
    const ids: string[] = [];
    const queueKey = this.getQueueKey(queueName);
    
    try {
      for (const jobData of jobs) {
        const job: QueueJob<T> = {
          id: `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
          type: jobData.type,
          data: jobData.data,
          priority: jobData.priority ?? 0,
          attempts: 0,
          maxAttempts: 3,
          createdAt: Date.now()
        };
        
        await redisService.lPush(queueKey, JSON.stringify(job));
        ids.push(job.id);
      }
      
      logger.debug(`Redis Queue: Batch of ${ids.length} jobs added to ${queueName}`);
      return ids;
    } catch (error: any) {
      logger.error(`Redis Queue: Failed to add batch to ${queueName}:`, error.message);
      throw error;
    }
  }
  
  /**
   * Register a processor for a queue
   * Starts polling for jobs in that queue
   */
  process(queueName: string, processor: JobProcessor): void {
    this.processors.set(queueName, processor);
    
    // Start polling for this queue if not already running
    if (!this.pollIntervals.has(queueName)) {
      this.startPolling(queueName);
    }
    
    logger.info(`Redis Queue: Processor registered for ${queueName}`);
  }
  
  /**
   * Start polling a queue for jobs
   */
  private startPolling(queueName: string): void {
    const poll = async () => {
      if (this.processing.size >= this.concurrency) return;
      
      const processor = this.processors.get(queueName);
      if (!processor) return;
      
      try {
        const queueKey = this.getQueueKey(queueName);
        
        // RPOP to get oldest job (FIFO)
        const jobStr = await redisService.rPop(queueKey);
        
        if (jobStr) {
          const job: QueueJob = JSON.parse(jobStr);
          
          // Check if job should be delayed
          if (job.processAfter && Date.now() < job.processAfter) {
            // Re-queue for later
            await redisService.lPush(queueKey, JSON.stringify(job));
            return;
          }
          
          this.processing.add(job.id);
          await this.processJob(queueName, job, processor);
        }
      } catch (error: any) {
        logger.error(`Redis Queue: Polling error for ${queueName}:`, error.message);
      }
    };
    
    const intervalId = setInterval(poll, this.pollInterval);
    this.pollIntervals.set(queueName, intervalId);
    
    // Initial poll
    poll();
  }
  
  /**
   * Process a single job
   */
  private async processJob(
    queueName: string, 
    job: QueueJob, 
    processor: JobProcessor
  ): Promise<void> {
    try {
      job.attempts++;
      await processor(job);
      
      this.emit('job:completed', { queueName, job });
      logger.debug(`Redis Queue: Job ${job.id} completed (${queueName})`);
      
    } catch (error: any) {
      job.error = error.message;
      
      if (job.attempts >= job.maxAttempts) {
        // Max retries reached - move to dead letter queue
        const dlqKey = this.getDeadLetterKey(queueName);
        await redisService.lPush(dlqKey, JSON.stringify(job));
        
        this.emit('job:failed', { queueName, job, error: error.message });
        logger.error(`Redis Queue: Job ${job.id} failed permanently, moved to DLQ`);
      } else {
        // Re-queue with exponential backoff
        job.processAfter = Date.now() + Math.pow(2, job.attempts) * 1000;
        const queueKey = this.getQueueKey(queueName);
        await redisService.lPush(queueKey, JSON.stringify(job));
        
        this.emit('job:retry', { queueName, job, attempt: job.attempts });
        logger.warn(`Redis Queue: Job ${job.id} failed, retry ${job.attempts}/${job.maxAttempts}`);
      }
    } finally {
      this.processing.delete(job.id);
    }
  }
  
  /**
   * Start processing (called automatically when processor is registered)
   */
  start(): void {
    this.isRunning = true;
    logger.info('üöÄ Redis Queue processor started');
  }
  
  /**
   * Stop processing jobs
   */
  stop(): void {
    this.isRunning = false;
    
    // Clear all polling intervals
    for (const [queueName, intervalId] of this.pollIntervals) {
      clearInterval(intervalId);
      logger.debug(`Redis Queue: Stopped polling for ${queueName}`);
    }
    this.pollIntervals.clear();
    
    logger.info('‚èπÔ∏è Redis Queue processor stopped');
  }
  
  /**
   * Get queue stats
   */
  async getStats(): Promise<{
    queues: { name: string; pending: number; processing: number }[];
    totalPending: number;
    totalProcessing: number;
  }> {
    const queueStats: { name: string; pending: number; processing: number }[] = [];
    
    for (const queueName of this.processors.keys()) {
      const queueKey = this.getQueueKey(queueName);
      const pending = await redisService.lLen(queueKey);
      
      queueStats.push({
        name: queueName,
        pending,
        processing: 0 // Redis doesn't track in-flight easily
      });
    }
    
    return {
      queues: queueStats,
      totalPending: queueStats.reduce((sum, q) => sum + q.pending, 0),
      totalProcessing: this.processing.size
    };
  }
}

// =============================================================================
// QUEUE INTERFACE (Unified type for both implementations)
// =============================================================================

interface IQueue {
  add<T>(queueName: string, type: string, data: T, options?: { priority?: number; delay?: number; maxAttempts?: number }): Promise<string>;
  addBatch<T>(queueName: string, jobs: { type: string; data: T; priority?: number }[]): Promise<string[]>;
  process(queueName: string, processor: JobProcessor): void;
  start(): void;
  stop(): void;
  getStats(): any;
}

// =============================================================================
// QUEUE SERVICE (Unified Interface - Auto-selects Redis in Production)
// =============================================================================

class QueueService {
  private queue: IQueue;
  private isRedisMode: boolean = false;
  
  // Queue names for organization
  static readonly QUEUES = {
    BROADCAST: 'broadcast',           // Broadcast notifications to transporters
    PUSH_NOTIFICATION: 'push',        // FCM push notifications
    EMAIL: 'email',                   // Email notifications (future)
    SMS: 'sms',                       // SMS notifications (future)
    ANALYTICS: 'analytics',           // Analytics events
    CLEANUP: 'cleanup',               // Cleanup/maintenance tasks
    CUSTOM_BOOKING: 'custom-booking'  // Custom booking events
  };
  
  constructor() {
    // PRODUCTION: Auto-select Redis queue if available
    // SCALABILITY: Redis queue persists across restarts, shared across ECS tasks
    const isProduction = process.env.NODE_ENV === 'production';
    const redisEnabled = process.env.REDIS_ENABLED === 'true';
    
    if (isProduction && redisEnabled) {
      this.queue = new RedisQueue();
      this.isRedisMode = true;
      logger.info('‚úÖ Queue Service: Using Redis Queue (Production Mode)');
    } else {
      this.queue = new InMemoryQueue();
      this.isRedisMode = false;
      logger.info('üì¶ Queue Service: Using In-Memory Queue (Development Mode)');
    }
    
    this.registerDefaultProcessors();
  }
  
  /**
   * Register default job processors
   */
  private registerDefaultProcessors(): void {
    // Broadcast processor
    this.queue.process(QueueService.QUEUES.BROADCAST, async (job) => {
      const { emitToUser } = require('./socket.service');
      const { transporterId, event, data } = job.data;
      emitToUser(transporterId, event, data);
    });
    
    // Push notification processor
    this.queue.process(QueueService.QUEUES.PUSH_NOTIFICATION, async (job) => {
      const { sendPushNotification } = require('./fcm.service');
      const { userId, notification } = job.data;
      await sendPushNotification(userId, notification);
    });
    
    logger.info('üìã Queue processors registered');
  }
  
  /**
   * Queue a broadcast to a transporter
   */
  async queueBroadcast(
    transporterId: string, 
    event: string, 
    data: any,
    priority: number = 0
  ): Promise<string> {
    return this.queue.add(
      QueueService.QUEUES.BROADCAST,
      'broadcast',
      { transporterId, event, data },
      { priority }
    );
  }
  
  /**
   * Queue broadcasts to multiple transporters (batch)
   */
  async queueBroadcastBatch(
    transporterIds: string[],
    event: string,
    data: any
  ): Promise<string[]> {
    const jobs = transporterIds.map(transporterId => ({
      type: 'broadcast',
      data: { transporterId, event, data },
      priority: 0
    }));
    
    return this.queue.addBatch(QueueService.QUEUES.BROADCAST, jobs);
  }
  
  /**
   * Queue a push notification
   */
  async queuePushNotification(
    userId: string,
    notification: {
      title: string;
      body: string;
      data?: Record<string, string>;
    }
  ): Promise<string> {
    return this.queue.add(
      QueueService.QUEUES.PUSH_NOTIFICATION,
      'push',
      { userId, notification },
      { maxAttempts: 3 }
    );
  }
  
  /**
   * Queue push notifications to multiple users (batch)
   */
  async queuePushNotificationBatch(
    userIds: string[],
    notification: {
      title: string;
      body: string;
      data?: Record<string, string>;
    }
  ): Promise<string[]> {
    const jobs = userIds.map(userId => ({
      type: 'push',
      data: { userId, notification },
      priority: 0
    }));
    
    return this.queue.addBatch(QueueService.QUEUES.PUSH_NOTIFICATION, jobs);
  }
  
  /**
   * Add custom job (full method name)
   */
  async addJob<T>(
    queueName: string,
    type: string,
    data: T,
    options?: { priority?: number; delay?: number; maxAttempts?: number }
  ): Promise<string> {
    return this.queue.add(queueName, type, data, options);
  }
  
  /**
   * Add job to queue (alias for addJob)
   * 
   * EASY UNDERSTANDING: Shorter method name for convenience
   * CODING STANDARDS: Matches common queue library patterns
   */
  async add<T>(
    queueName: string,
    type: string,
    data: T,
    options?: { priority?: number; delay?: number; maxAttempts?: number }
  ): Promise<string> {
    return this.queue.add(queueName, type, data, options);
  }
  
  /**
   * Register custom processor
   */
  registerProcessor(queueName: string, processor: JobProcessor): void {
    this.queue.process(queueName, processor);
  }
  
  /**
   * Get queue statistics
   */
  getStats() {
    return this.queue.getStats();
  }
  
  /**
   * Stop all queue processing
   */
  stop(): void {
    this.queue.stop();
  }
}

// Export singleton
export const queueService = new QueueService();
